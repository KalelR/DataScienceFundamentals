{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40618b7-100d-4fbe-ad18-85f40b9c1c40",
   "metadata": {},
   "source": [
    "# 3.4 - How to choose the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c142a80-8308-44c5-ae0d-bf5216c5124f",
   "metadata": {},
   "source": [
    "## Selecting the best hyperparameters\n",
    "How to decide on the best hyperparameters while ensuring that the models are generalizable?\n",
    "\n",
    "\n",
    "### Train/Test Split\n",
    "A first naive approach would be to train the model using the whole dataset and then just compute an accuracy measure on the dataset (e.g. the MSE). An then to choose the model's hyperparameters such that the accuracy is maximized. \n",
    "However, there is a strong possibility that the model's parameters are then chosen to maximize accuracy on that specific dataset, leading to *overfitting*. If that model is applied to another dataset, there is no guarantee it will perform well.\n",
    "\n",
    "An improvement to this is to split the dataset into two parts: one used for training, another for testing the model's performance. But overfitting can still occur here, as we'd choose the hyperparameters based on performance on the same test set.\n",
    "\n",
    "To avoid overfitting, and *ensure better generalizability* of the dataset, we can split it into three disjointed parts: \n",
    "- training part: a part for training the model (e.g., estimating the coefficients for regression),\n",
    "- validation part: for evaluating the model's performance and tuning hyperparameters,\n",
    "- test part: after deciding on the hyperparameters, used to estimate the final accuracy of the model.\n",
    "\n",
    "![Alt text](images/validation.png)\n",
    "\n",
    "\n",
    "These parts are usually chosen randomly from the dataset. This can lead to biased results if, by bad luck, either of them don't represent the full dataset. Further, it is, in a way, a shame that we have to use the validation part, because it could be used in training to provide a more accurate model. A way to to solve this is k-fold cross validation.\n",
    "\n",
    "### K-fold Cross-validation\n",
    "\n",
    "Now we first split the dataset into two disjointed parts:\n",
    "- training+validation\n",
    "- test\n",
    "\n",
    "Then, we subdivide the training+validation into k equally sized chunks (called folds). Of these k folds, k-1 are used for training, and 1 is used for validation (like in the train/test split). But the idea here is that we perform this procedure $k$ times, assigning each time the validation set to one of the folds. Then, the final accuracy estimation is an average over the accuracies of each of the $k$ iterations. \n",
    "\n",
    "![Alt text](images/validation-folds.png)\n",
    "\n",
    "See https://scikit-learn.org/stable/modules/cross_validation.html for examples!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a2e14-818b-4ced-84fc-dda8b1a75477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Example dataset (you'll replace this with your actual data)\n",
    "X = np.array([[1, 2], [3, 5], [5, 4], [8, 2]])  # Features\n",
    "y = np.array([3, 8, 6, 10])  # Target values\n",
    "\n",
    "# Split into training and testing sets (optional for evaluation)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=3)  # Set k to 3 \n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "new_points = np.array([[2, 3], [6, 3]])  # Example new data for prediction\n",
    "predictions = knn.predict(new_points)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200c095-dde9-4949-9111-25c9557b5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with cross-validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
