{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ae38b1-8859-46c1-aa34-637aab9ae596",
   "metadata": {},
   "source": [
    "# 3.2 - How good are the model predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640f90f-b249-4c50-80c5-de1a3dedf20a",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "For a dataset with true values $y$ and a model with corresponding predictions $\\hat{y}$ and $N$ data poitns, we can define\n",
    "- Residuals: $e_i = y_i - \\hat{y}_i$.\n",
    "- Residual sum of squares (RSS, SRR): $RSS = \\sum_i e_i^2 = \\sum_i (y_i - \\hat{y}_i)^2$. In a way, amount of variance that the model does not capture (deviation from the predictions). \n",
    "- Mean square error (MSE): $MSE = RSS/N = 1/N \\sum_i e_i^2 = 1/N \\sum_i (y_i - \\hat{y}_i)^2$.\n",
    "- Total sum of squares (TSS): $TSS = \\sum_i (y_i - \\overline{y})^2$, for $\\overline{y} = \\mathrm{mean}(y_i)$. Proportional to the variance of the data (how much the values deviate from the average).\n",
    "- R squared (R^2): $R^2 = \\frac{TSS-RSS}{TSS} = 1 - \\frac{RSS}{TSS} = 1 - \\frac{\\sum_i (y_i - \\hat{y}_i)^2}{\\sum(y_i - \\overline{y})^2}$. The model has no control over $TSS$, it is just a property of the dataset. But it does have control over $RSS$, which you want to minimize. Therefore, $R^2 \\to 1$ has smaller error, while $R^2 \\to 0$ has more error. Looking at the equation, one can also interpret the ratio as how well the model does compared to a naive model that just takes the average over the dataset. Also can be interpreted as the relative amount of the total variance in the data that the model successfully captures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3060fef8-71c5-40ce-b076-6ae85ed1b000",
   "metadata": {},
   "source": [
    "## Classification \n",
    "A binary (positive/negative) classification model can commit two types of errors and two types of successes:\n",
    "\n",
    "![](images/confusion-matrix.png)\n",
    "\n",
    "This table is known as a confusion matrix. Based on it, we can define several measurements of model outcome:\n",
    "- _Accuracy_: out of all predictions, how many are correct; i.e, the percentage of true, accurate, predictions: $\\mathrm{accuracy} = \\frac{TN + TP}{TN+TP+FN+FP}$; e.g.: how many of the test results did we get right?\n",
    "\n",
    "- _Sensitivity_ (recall, true positive rate): out of all true positive results, how many did we predict correctly? i.e., true positive rate: $\\mathrm{sensitivity} = \\frac{TN}{TP+FN}$; e.g.: how many people with the disease did we identify?\n",
    "\n",
    "- _Precision_: out of all our predictions of true, how many are actually true? $\\mathrm{precision} = \\frac{TP}{TP+FP}$; e.g., when our test predicts positive, what is the chance you actually have it?\n",
    "\n",
    "- _F1 score_: harmonic mean of precision and sensitivity, higher values indicate a good balance; $\\mathrm{F1 score} = \\frac{2 \\mathrm{precision} * \\mathrm{sensitivity}}{\\mathrm{precision} + \\mathrm{recall}}$. Maximum value is 1 (perfect model), minimum is 0\n",
    "\n",
    "- _False positive rate_ (FPR): out of all true negative values, how many did we predict incorrectly? $\\mathrm{FPR} = \\frac{FP}{FP+TN}$; for everyone that tested and did not have the disease, how many did we say had?\n",
    "\n",
    "### ROC curve\n",
    "Classification models have a threshold (Bayes threshold) to define whether the response variable is true or not from the probability $p(x)$ that it is true. For each threshold, we get a false positive rate and a true positive rate - ideally, we want to have the highest true positive rate while minimizing the false positive rate. To find this optimal, calculate these rates for several thresholds and then plot them together, in what is known as an ROC curve.\n",
    "\n",
    "![](images/roc.png)\n",
    "\n",
    "The area under the ROC curve (AUC) gives a threshold-free estimate of the quality of a model: AUC closer to 1 is closer to the ideal case, AUC closer to 0 is bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d67e5-6289-4e33-8dc2-917ae673cf85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22568148-8582-44b8-a6a8-3713c3c4364e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
